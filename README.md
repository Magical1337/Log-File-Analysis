# 📊 Log File Analysis with Bash

This project provides a Bash-based solution for analyzing Apache-style access log files. It generates useful insights and trends about web traffic, failure patterns, and usage statistics.

## 📓 Files Included

* `analyze_log.sh` – Main Bash script that performs the analysis.
* `sample_access.log` – Sample log file used as input.
* `log_analysis_report.txt` – Output report generated by the script with full insights.

---

## ✨ Features

The script performs the following:

* ✅ Count of total, GET, and POST requests
* 🌐 Total unique IP addresses and their request types
* ❌ Failed requests (4xx/5xx) and failure percentage
* 🏆 Most active IP (top user)
* 🗓️ Average number of requests per day
* ⏰ Hourly request breakdown
* ⬆️📈 Request trend analysis
* ⚖️ Status code frequency
* 👁️ Failure request patterns (hours/days)
* 💪 Most active user by request method
* 💡 Suggestions for improvements and anomalies

---

## 🚀 How to Use

1. **Clone the repository**:

   ```bash
   git clone https://github.com/yourusername/your-repo-name.git
   cd your-repo-name
   ```

2. **Make the script executable**:

   ```bash
   chmod +x analyze_log.sh
   ```

3. **Run the script**:

   ```bash
   ./analyze_log.sh
   ```

4. **Check the output**:
   Open `log_analysis_report.txt` to read the full analysis results.

---

## 📆 Example Output Highlights

* Total Requests: 13456
* GET Requests: 11423
* POST Requests: 2033
* Unique IPs: 872
* Top User IP: 192.168.0.101 (203 requests)
* Failure Rate: 7.2%
* Most Failures: 2025-05-09 (312 failed requests)
* Peak Hour: 14:00-15:00

---

## 📅 Suggestions Based on Analysis

* Investigate IPs generating high numbers of requests in short time spans.
* Implement rate limiting during peak hours.
* Address recurring 4xx/5xx failures by reviewing endpoint behavior.
* Use monitoring to track spikes in failure on specific days.

---

## 🚨 Requirements

* Bash (Unix-based systems) or Git Bash for Windows.
* Standard Unix tools: `awk`, `grep`, `sort`, `uniq`, `cut`, `date`.
